{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided self-learning project from Hands-On Introduction to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a *guided* self-learning project I have done, using the book \"Hands-on Introduction to Machine Learning[...]\".\n",
    "\n",
    "<b> Project summary </b> <br>\n",
    "The goal is to find a model for house prices prediction, given a sample dataset. We test Linear Regressor, Decision Tree and Random Forest. <br>\n",
    "<b> The plan of the project:</b>\n",
    "1. Basic data exploration. <br>\n",
    "2. Cleaning the data - adding/removing attributes, imputing missing values, encoding categorical attributes as numerical. <br>\n",
    "3. Performing regression - splitting into train and test set, running models, testing performance and overfit. <br>\n",
    "4. Final answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and copy the dataset\n",
    "housing_orig = pd.read_csv('housing.csv')\n",
    "housing = housing_orig.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a quick glance on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 numeric attributes, except one categorical \"ocean_proximity\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values: only in attribute total_bedrooms, 207 missing values (ca. 1% of this column). <br>\n",
    "Imputing strategy: median (done later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem with dataset that we ignore (<b> Fig.1 </b>): numeric data have suspiciously lot of observations with maximal value (in attributes housing_media_age on value 50 and attribute median_house_value on value 500)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem with the dataset that we fix later: very few observations with value ISLAND in categorical attribute ocean_proximity (5 out of ca. 20 000, ca. 0.03%). In consequence this value often does not occur in the test set; as a solution we manually pick the random seed used for the split into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.ocean_proximity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fig1: Too many maximal values in housing_median_age and median_house_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.hist(bins=50,figsize=(20,15));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.2 #size of test set w.r.t. whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set3, test_set3 = train_test_split(housing, test_size=test_ratio, random_state=6)#seed 6 chosen in order to have all values of all (1) categorical attributes in both train set and test set (explicitly: ISLAND value of ocean_proximity attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if all values of ocean_proximity are in both train and test set\n",
    "if len(np.unique(housing.ocean_proximity.values)) == len(np.unique(test_set3.ocean_proximity.values)):\n",
    "    print(\"OK - test set contains all values of categorical atributes.\")\n",
    "else:\n",
    "    print(\"Bad - test set misses some values of categorical atributes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding/removing parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A glance on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will <b> add/drop parameters </b>, that appear <b> logically more relevant/irrelevant</b> as predictors of house prices. <br>\n",
    "We <b> add attributes: </b> rooms per household, bedrooms per household, and bedrooms per room (the last one is determined by the previous two). <br>\n",
    "We <b> drop attributes: </b> total_rooms, total_bedrooms, longitude, latitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our attribute transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class AttributeAdderAndRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, before_cat_encoding):\n",
    "        self.before_cat_encoding = before_cat_encoding\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        #we add new attributes and we remove four irrelevant ones\n",
    "        X[\"rooms_per_household\"] = X.total_rooms/X.households\n",
    "        X[\"bedrooms_per_household\"] = X.total_bedrooms/X.households\n",
    "        X[\"bedrooms_per_room\"] = X.total_bedrooms/X.total_rooms\n",
    "        X.drop([\"total_rooms\", \"total_bedrooms\", \"longitude\", \"latitude\"], axis=1, inplace=True)#drop irrelevant attributes\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxilliary functions (attributes lists and array-to-dataframe function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns\n",
    "## categorical columns ##\n",
    "old_cat_columns = [\"ocean_proximity\"]\n",
    "new_cat_columns = list(np.unique(train_set3.copy()[old_cat_columns[0]].values)) #or statically: ['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN']\n",
    "all_cat_columns = old_cat_columns + new_cat_columns\n",
    "# auxilliary function\n",
    "def wo_cat_columns(L:list):#without categorical columns\n",
    "    return [col_name for col_name in L if col_name not in all_cat_columns]\n",
    "\n",
    "## numerical columns ##\n",
    "old_columns = list(housing_orig.columns)\n",
    "old_num_columns = wo_cat_columns(old_columns)\n",
    "new_num_columns = wo_cat_columns(list(AttributeAdderAndRemover(before_cat_encoding=True).fit_transform(housing_orig.copy()).columns))\n",
    "\n",
    "## new columns ##\n",
    "new_columns = new_num_columns + new_cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_to_DataFrame(X, before_cat_encoding:bool, before_attr_transforming:bool):\n",
    "    \"\"\"\n",
    "    Turns an array to a DataFrame by adding column names.\n",
    "    \"\"\"\n",
    "    if before_cat_encoding:\n",
    "        if before_attr_transforming:\n",
    "            raise(NotImplementedError)\n",
    "        else:\n",
    "            return pd.DataFrame(X, columns=old_columns, index = range(len(X)))\n",
    "    else:\n",
    "        return pd.DataFrame(X, columns=new_columns, index = range(len(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing and encoding categorical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical attributes are imputed using median strategy. <br>\n",
    "Categorical attributes are encoded into vectors using one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define transformers that build the pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "my_attribute_transformer = AttributeAdderAndRemover(before_cat_encoding=True)\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "cat_encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define pipelines\n",
    "col_pipeline = ColumnTransformer([\n",
    "    ('num', imputer, new_num_columns), #impute\n",
    "    ('cat', cat_encoder, old_cat_columns) #encode categorical as numerical\n",
    "])\n",
    "full_pipeline = Pipeline([\n",
    "    ('attr_transformer', my_attribute_transformer), #add/remove attributes\n",
    "    ('imput-cat_encode', col_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run pipeline, obtaining an array\n",
    "housing_train = train_set3.copy()\n",
    "housing_prepared_plus_labels = full_pipeline.fit_transform(housing_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final objects, ready for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating final objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert array to DataFrame\n",
    "housing_prepared_plus_labels_as_df = our_to_DataFrame(housing_prepared_plus_labels, before_cat_encoding=False, before_attr_transforming=False)\n",
    "#final objects\n",
    "label_attrs = [\"median_house_value\"]\n",
    "housing_prepared = housing_prepared_plus_labels_as_df.drop(label_attrs, axis=1)\n",
    "housing_labels = housing_prepared_plus_labels_as_df[label_attrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train three models: Linear Regression, Decision Tree, Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Linear Regressor\", \"Decision Tree Regressor\", \"Random Forest Regressor\"]\n",
    "models_list = [LinearRegression(), DecisionTreeRegressor(), RandomForestRegressor()]#mutable objects (a reminder)\n",
    "models = dict(zip(names, models_list)) #dictionary name:model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models_list:\n",
    "    model.fit(housing_prepared, housing_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing performance and overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auxilliary function\n",
    "def name_of_min(d:dict):\n",
    "    #we assume values are comparable\n",
    "    #\n",
    "    #take first value as cur_min\n",
    "    for name, val in d.items():\n",
    "        cur_min = name, val\n",
    "        break\n",
    "    #search for real min\n",
    "    for name, val in d.items():\n",
    "        if val < cur_min[1]:\n",
    "            cur_min = name, val\n",
    "    #\n",
    "    return cur_min[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfit test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the overfit of a model by its performance on a train set - the better the performance, the more overfitted we find the model. This is <b> not exactly   what overfit means</b>, nevertheless, in this project we apply this simple, yet inaccurate method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_on_train_set = dict()\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"Overfit test (RMSE on train set).\")\n",
    "for nazwa, model in models.items():\n",
    "    predicted_labels = model.predict(housing_prepared)\n",
    "    mse = mean_squared_error(housing_labels, predicted_labels)\n",
    "    rmse = np.sqrt(mse)\n",
    "    rmses_on_train_set[nazwa] = rmse\n",
    "    print('RMSE of model', nazwa, ':', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "housing_test = test_set3.copy().reset_index().drop([\"index\"], axis=1)\n",
    "#run pipeline\n",
    "housing_test_prepared_plus_labels = full_pipeline.fit_transform(housing_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final object\n",
    "housing_test_prepared_plus_labels_as_df = our_to_DataFrame(housing_test_prepared_plus_labels, before_cat_encoding=False, before_attr_transforming=False)\n",
    "#recall: label_attrs = [\"median_house_value\"]\n",
    "housing_test_prepared = housing_test_prepared_plus_labels_as_df.drop(label_attrs, axis=1)\n",
    "housing_test_labels = housing_test_prepared_plus_labels_as_df[label_attrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_on_test_set = dict()\n",
    "print(\"Performance on test set (RMSE) \")\n",
    "for nazwa, model in models.items():\n",
    "    predicted_test_labels = model.predict(housing_test_prepared)\n",
    "    mse = mean_squared_error(housing_test_labels, predicted_test_labels)\n",
    "    rmse = np.sqrt(mse)\n",
    "    rmses_on_test_set[nazwa] = rmse\n",
    "    print('RMSE of model', nazwa, ':', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_best_model = name_of_min(rmses_on_test_set)\n",
    "print('Best performing model: ', name_of_best_model, '.',sep=\"\")\n",
    "print('Most overtrained model: ', name_of_min(rmses_on_train_set), '.', sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(models[name_of_best_model], \"best_model.pkl\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
